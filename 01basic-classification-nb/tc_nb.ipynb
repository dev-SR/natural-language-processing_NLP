{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Basic Text Classification using Naive Baye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "cd .\\01basic-classification-nb\\\n",
    "jupyter nbconvert --to markdown tc_nb.ipynb --output README.md\n",
    "\"\"\"\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Textual Data Cleaning I - NLP Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \"\"\"I loved this movie <br /><br /> since I was 7 and I saw it on the opening day. It was so touching and beautiful. I strongly recommend seeing for all. It's a movie to watch with your family by far.<br /><br />My MPAA rating: PG-13 for thematic elements, prolonged scenes of disastor, nudity/sexuality and some language.\"\"\"\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "en_stopwords = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCleanReview(review):\n",
    "\n",
    "    review = review.lower()\n",
    "    review = review.replace(\"<br /><br />\", \" \")\n",
    "\n",
    "    # Tokenize\n",
    "    tokens = tokenizer.tokenize(review)\n",
    "    new_tokens = [token for token in tokens if token not in en_stopwords]\n",
    "    stemmed_tokens = [ps.stem(token) for token in new_tokens]\n",
    "\n",
    "    cleaned_review = ' '.join(stemmed_tokens)\n",
    "\n",
    "    return cleaned_review\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'love movi sinc 7 saw open day touch beauti strongli recommend see movi watch famili far mpaa rate pg 13 themat element prolong scene disastor nuditi sexual languag'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getCleanReview(sample_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Textual Data Cleaning II - Working with Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStemmedDocument(inputFile):\n",
    "\n",
    "    outputFile = inputFile.replace(\".txt\", \"_stemmed.txt\")\n",
    "    out = open(outputFile, 'w', encoding=\"utf8\")\n",
    "\n",
    "    with open(inputFile, encoding=\"utf8\") as f:\n",
    "        reviews = f.readlines()\n",
    "\n",
    "    for review in reviews:\n",
    "        cleaned_review = getCleanReview(review)\n",
    "        print((cleaned_review), file=out)\n",
    "\n",
    "    out.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "getStemmedDocument(\"imdb_toy_x.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Running in CLI\n",
    "\n",
    "```\n",
    "cd .\\01basic-classification-nb\\\n",
    "conda activate base\n",
    "python clean_reviews.py imdb_toy_x.txt\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie Review Prediction - Using Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = [\"This was an awesome movie\",\n",
    "\t\"Great movie! I liked it a lot\",\n",
    "\t\"Happy Ending! awesome acting by the hero\",\n",
    "\t\"loved it! truly great\",\n",
    "\t\"bad not upto the mark\",\n",
    "\t\"could have been better\",\n",
    "\t\"Surely a Disappointing movie\"\n",
    "]\n",
    "\n",
    "y = [1,1,1,1,0,0,0] # 1 - Positive, 0 - Negative Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = [\"I was happy & happy and I loved the acting in the movie\",\n",
    "\t\t\"The movie I saw bad\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_clean = [getCleanReview(i) for i in x]\n",
    "X_test_clean = [getCleanReview(i) for i in x_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['awesom movi',\n",
       "  'great movi like lot',\n",
       "  'happi end awesom act hero',\n",
       "  'love truli great',\n",
       "  'bad upto mark',\n",
       "  'could better',\n",
       "  'sure disappoint movi'],\n",
       " ['happi happi love act movi', 'movi saw bad'])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_clean, X_test_clean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0]\n",
      " [1 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1]\n",
      " [0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0]]\n",
      "(7, 18)\n"
     ]
    }
   ],
   "source": [
    "x_vec = cv.fit_transform(X_train_clean).toarray()\n",
    "print(x_vec)\n",
    "print(x_vec.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['act', 'awesom', 'bad', 'better', 'could', 'disappoint', 'end', 'great', 'happi', 'hero', 'like', 'lot', 'love', 'mark', 'movi', 'sure', 'truli', 'upto']\n"
     ]
    }
   ],
   "source": [
    "print(cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Watch Out on Vectorization of Test Data using `fit_transform`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 6)\n",
      "['act', 'bad', 'happi', 'love', 'movi', 'saw']\n"
     ]
    }
   ],
   "source": [
    "x_test_vec = cv.fit_transform(X_test_clean).toarray()\n",
    "print(x_test_vec.shape)\n",
    "print(cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 18)\n"
     ]
    }
   ],
   "source": [
    "x_vec = cv.fit_transform(X_train_clean).toarray()\n",
    "x_test_vec = cv.transform(X_test_clean).toarray()\n",
    "print(x_test_vec.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Why-we-use-`fit_transform()-`on-**training**-data-but-`transform()`-on-the-**test**-data?](https://towardsdatascience.com/what-and-why-behind-fit-transform-vs-transform-in-scikit-learn-78f915cf96fe)\n",
    "\n",
    "\n",
    "[stackoverflow/what-is-the-difference-between-transform-and-fit-transform-in-sklearn](https://stackoverflow.com/questions/23838056/what-is-the-difference-between-transform-and-fit-transform-in-sklearn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `transform` method we can use the same `mean` and `variance` as it is calculated from our **training** data to transform our test data. Thus, the parameters learned by our model using the training data will help us to transform our test data.\n",
    "\n",
    "Generic difference between the methods:\n",
    "\n",
    "- `fit(raw_documents[, y])`: Learn a vocabulary dictionary of all tokens in the raw documents.\n",
    "- `fit_transform(raw_documents[, y]):` Learn the vocabulary dictionary and return term-document matrix. This is equivalent to fit followed by the transform, but more efficiently implemented.\n",
    "- `transform(raw_documents)`: Transform documents to document-term matrix. Extract token counts out of raw text documents using the vocabulary fitted with fit or the one provided to the constructor(from our **training** data).\n",
    "- Both fit_transform and transform returns the same, Document-term matrix.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model using the training sets\n",
    "mnb.fit(x_vec, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.predict(x_test_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`[1,0]` = `[Positive Review , Negative Review]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.score(x_vec, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimenting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = [\"I was happy & happy and I loved the acting in the movie\",\n",
    "\t\t\"The movie I saw not bad\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 18)\n",
      "['happi happi love act movi', 'movi saw bad']\n",
      "(2, 18)\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "# fit_transform() is must other wise `transform()` will not work\n",
    "x_vec = cv.fit_transform(X_train_clean).toarray()\n",
    "print(x_vec.shape)\n",
    "\n",
    "X_test_clean = [getCleanReview(i) for i in x_test]\n",
    "print(X_test_clean)\n",
    "\n",
    "x_test_vec = cv.transform(X_test_clean).toarray()\n",
    "print(x_test_vec.shape)\n",
    "# print(cv.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Stopwords` removed `not` . We can see the after `stopwords` the negative reviews also changed to positive. A bit scary right?\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.fit(x_vec, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.predict(x_test_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`[1,0]` = `[Positive Review , Negative Review]` but last one should be also `Positive` Review. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[https://dev.to/sunilaleti/don-t-blindly-remove-stopwords-in-sentiment-analysis-3nok](https://dev.to/sunilaleti/don-t-blindly-remove-stopwords-in-sentiment-analysis-3nok)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8cdb09b0bc1c395d296938b19fe7764d972a7ceeffba4d3ad7ff6a3771581719"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('ProgramData': virtualenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
